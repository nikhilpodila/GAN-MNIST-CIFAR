{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "s7bjogNte65I",
    "outputId": "a8ba499d-92b8-4177-d0d3-64b0c47d524e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "#Importing the required libraries \n",
    "%matplotlib inline\n",
    "import numpy  as np  \n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import keras\n",
    "import h5py\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import glob\n",
    "\n",
    "from keras.datasets import mnist, fashion_mnist\n",
    "\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras.callbacks import ModelCheckpoint, Callback\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential\n",
    "from keras.models import load_model\n",
    "\n",
    "from keras.layers import Input, Dense, TimeDistributed\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense, Dropout, Reshape, Flatten, BatchNormalization\n",
    "from keras.layers import Conv2D, MaxPooling2D, Activation, MaxPool2D, Convolution2D, UpSampling2D, Conv2DTranspose, ZeroPadding2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "from keras.utils import np_utils\n",
    "from keras.utils.np_utils import to_categorical,normalize\n",
    "\n",
    "from keras import optimizers\n",
    "from keras.optimizers import SGD, RMSprop, Adam, Nadam\n",
    "\n",
    "import pickle\n",
    "#from sklearn.model_selection import train_test_split\n",
    "#from sklearn.metrics import classification_report, confusion_matrix\n",
    "#from sklearn.metrics import accuracy_score\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import datetime\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "iOjq9v7pfED8",
    "outputId": "b4ae0811-22fc-46be-aaed-6849b4262e94"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive',force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 334
    },
    "colab_type": "code",
    "id": "mqdfAQG1fGZl",
    "outputId": "1cd2759c-d838-4a57-b7aa-cd8d841ac0af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shell-init: error retrieving current directory: getcwd: cannot access parent directories: Transport endpoint is not connected\n",
      "Wed Dec 11 01:13:05 2019       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 440.36       Driver Version: 418.67       CUDA Version: 10.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   74C    P8    35W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gmRQycYlfLaw"
   },
   "outputs": [],
   "source": [
    "os.chdir(\"/content/drive/My Drive/MiniProject4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FvxC0GnohdKS"
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout\n",
    "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "import keras.backend as K\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "class WGAN():\n",
    "    def __init__(self):\n",
    "        self.img_rows = 28\n",
    "        self.img_cols = 28\n",
    "        self.channels = 1\n",
    "        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n",
    "        self.latent_dim = 100\n",
    "        self.losses = {\"D_real\":[], \"D_fake\":[] ,\"G\":[]}\n",
    "\n",
    "        # Following parameter and optimizer set as recommended in paper\n",
    "        self.n_critic = 5\n",
    "        self.clip_value = 0.01\n",
    "        optimizer = RMSprop(lr=0.00005)\n",
    "\n",
    "        # Build and compile the critic\n",
    "        self.critic = self.build_critic()\n",
    "        self.critic.compile(loss=self.wasserstein_loss,\n",
    "            optimizer=optimizer,\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "        # Build the generator\n",
    "        self.generator = self.build_generator()\n",
    "\n",
    "        # The generator takes noise as input and generated imgs\n",
    "        z = Input(shape=(self.latent_dim,))\n",
    "        img = self.generator(z)\n",
    "\n",
    "        # For the combined model we will only train the generator\n",
    "        self.critic.trainable = False\n",
    "\n",
    "        # The critic takes generated images as input and determines validity\n",
    "        valid = self.critic(img)\n",
    "\n",
    "        # The combined model  (stacked generator and critic)\n",
    "        self.combined = Model(z, valid)\n",
    "        self.combined.compile(loss=self.wasserstein_loss,\n",
    "            optimizer=optimizer,\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "    def wasserstein_loss(self, y_true, y_pred):\n",
    "        return K.mean(y_true * y_pred)\n",
    "\n",
    "    def build_generator(self):\n",
    "\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Dense(128 * 7 * 7, activation=\"relu\", input_dim=self.latent_dim))\n",
    "        model.add(Reshape((7, 7, 128)))\n",
    "        model.add(UpSampling2D())\n",
    "        model.add(Conv2D(128, kernel_size=4, padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(UpSampling2D())\n",
    "        model.add(Conv2D(64, kernel_size=4, padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(Conv2D(self.channels, kernel_size=4, padding=\"same\"))\n",
    "        model.add(Activation(\"tanh\"))\n",
    "\n",
    "        model.summary()\n",
    "\n",
    "        noise = Input(shape=(self.latent_dim,))\n",
    "        img = model(noise)\n",
    "\n",
    "        return Model(noise, img)\n",
    "\n",
    "    def build_critic(self):\n",
    "\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Conv2D(16, kernel_size=3, strides=2, input_shape=self.img_shape, padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Conv2D(32, kernel_size=3, strides=2, padding=\"same\"))\n",
    "        model.add(ZeroPadding2D(padding=((0,1),(0,1))))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Conv2D(64, kernel_size=3, strides=2, padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Conv2D(128, kernel_size=3, strides=1, padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(1))\n",
    "\n",
    "        model.summary()\n",
    "\n",
    "        img = Input(shape=self.img_shape)\n",
    "        validity = model(img)\n",
    "\n",
    "        return Model(img, validity)\n",
    "\n",
    "    def train(self, epochs, batch_size=128, sample_interval=50):\n",
    "\n",
    "        # Load the dataset\n",
    "        (X_train, _), (_, _) = mnist.load_data()\n",
    "\n",
    "        # Rescale -1 to 1\n",
    "        X_train = (X_train.astype(np.float32) - 127.5) / 127.5\n",
    "        X_train = np.expand_dims(X_train, axis=3)\n",
    "\n",
    "        # Adversarial ground truths\n",
    "        valid = -np.ones((batch_size, 1))\n",
    "        fake = np.ones((batch_size, 1))\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "\n",
    "            for _ in range(self.n_critic):\n",
    "\n",
    "                # ---------------------\n",
    "                #  Train Discriminator\n",
    "                # ---------------------\n",
    "\n",
    "                # Select a random batch of images\n",
    "                idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
    "                imgs = X_train[idx]\n",
    "                \n",
    "                # Sample noise as generator input\n",
    "                noise = np.random.normal(0, 1, (batch_size, self.latent_dim))\n",
    "\n",
    "                # Generate a batch of new images\n",
    "                gen_imgs = self.generator.predict(noise)\n",
    "\n",
    "                # Train the critic\n",
    "                d_loss_real = self.critic.train_on_batch(imgs, valid)\n",
    "                d_loss_fake = self.critic.train_on_batch(gen_imgs, fake)\n",
    "                d_loss = 0.5 * np.add(d_loss_fake, d_loss_real)\n",
    "\n",
    "                # Clip critic weights\n",
    "                for l in self.critic.layers:\n",
    "                    weights = l.get_weights()\n",
    "                    weights = [np.clip(w, -self.clip_value, self.clip_value) for w in weights]\n",
    "                    l.set_weights(weights)\n",
    "\n",
    "\n",
    "            # ---------------------\n",
    "            #  Train Generator\n",
    "            # ---------------------\n",
    "\n",
    "            g_loss = self.combined.train_on_batch(noise, valid)\n",
    "\n",
    "            # Plot the progress\n",
    "            print (\"%d [D loss: %f] [G loss: %f]\" % (epoch, 1 - d_loss[0], 1 - g_loss[0]))\n",
    "            \n",
    "            self.losses[\"D_real\"].append(d_loss[0])\n",
    "            self.losses[\"D_fake\"].append(d_loss[1])\n",
    "            self.losses[\"G\"].append(g_loss)\n",
    "            #with open('WGAN_RMS.pickle', 'wb') as handle:\n",
    "              #pickle.dump(self.losses, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "            # If at save interval => save generated image samples\n",
    "            if epoch % sample_interval == 0:\n",
    "                self.sample_images(epoch)\n",
    "        self.plot_loss()\n",
    "\n",
    "    def gan_test(self, model_file, num_examples):\n",
    "        self.generator = self.build_generator()\n",
    "        self.generator.load_weights(model_file)\n",
    "        noise = np.random.normal(0, 1, (num_examples, self.latent_dim))\n",
    "        gen_imgs = self.generator.predict(noise)\n",
    "        \n",
    "        # Rescale images 0 - 1\n",
    "        gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "        print(gen_imgs.shape)\n",
    "        \n",
    "        for i in range(num_examples):\n",
    "            plt.imsave(\"./imgs/wgan/image\"+str(i)+\".png\", gen_imgs[i, :, :, 0], cmap = \"gray\")\n",
    "\n",
    "    def sample_images(self, epoch):\n",
    "        r, c = 5, 5\n",
    "        noise = np.random.normal(0, 1, (r * c, self.latent_dim))\n",
    "        gen_imgs = self.generator.predict(noise)\n",
    "\n",
    "        # Rescale images 0 - 1\n",
    "        gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "\n",
    "        fig, axs = plt.subplots(r, c)\n",
    "        cnt = 0\n",
    "        for i in range(r):\n",
    "            for j in range(c):\n",
    "                axs[i,j].imshow(gen_imgs[cnt, :,:,0], cmap='gray')\n",
    "                axs[i,j].axis('off')\n",
    "                cnt += 1\n",
    "        fig.savefig(\"images/wgan_%d.png\" % epoch)\n",
    "        plt.close()\n",
    "\n",
    "    def plot_loss(self):\n",
    "        d_loss = [v for v in self.losses[\"D_real\"]]\n",
    "        g_loss = [v for v in self.losses[\"G\"]]\n",
    "        #d_acc = [v[1] for v in losses[\"D\"]]\n",
    "        #g_acc = [v[1] for v in losses[\"G\"]]\n",
    "\n",
    "        plt.figure(figsize=(10,8))\n",
    "        plt.plot(d_loss, label=\"Discriminator loss\")\n",
    "        plt.plot(g_loss, label=\"Generator loss\")\n",
    "        #plt.plot(d_acc, label=\"Discriminator accuracy\")\n",
    "        #plt.plot(g_acc, label=\"Generator accuracy\")\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.title('WGAN RMS')\n",
    "        plt.legend()\n",
    "        plt.savefig(\"./WGAN_rms_loss.png\")\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "mzJRVO-WrKm9",
    "outputId": "7c8d6914-bb1f-4c8d-c4b7-a1c964941446"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_29 (Conv2D)           (None, 14, 14, 16)        160       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_17 (LeakyReLU)   (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_30 (Conv2D)           (None, 7, 7, 32)          4640      \n",
      "_________________________________________________________________\n",
      "zero_padding2d_5 (ZeroPaddin (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_21 (Batc (None, 8, 8, 32)          128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_18 (LeakyReLU)   (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_31 (Conv2D)           (None, 4, 4, 64)          18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_22 (Batc (None, 4, 4, 64)          256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_19 (LeakyReLU)   (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_32 (Conv2D)           (None, 4, 4, 128)         73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_23 (Batc (None, 4, 4, 128)         512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_20 (LeakyReLU)   (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 2049      \n",
      "=================================================================\n",
      "Total params: 100,097\n",
      "Trainable params: 99,649\n",
      "Non-trainable params: 448\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_10 (Dense)             (None, 6272)              633472    \n",
      "_________________________________________________________________\n",
      "reshape_5 (Reshape)          (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_9 (UpSampling2 (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_33 (Conv2D)           (None, 14, 14, 128)       262272    \n",
      "_________________________________________________________________\n",
      "batch_normalization_24 (Batc (None, 14, 14, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_10 (UpSampling (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_34 (Conv2D)           (None, 28, 28, 64)        131136    \n",
      "_________________________________________________________________\n",
      "batch_normalization_25 (Batc (None, 28, 28, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_35 (Conv2D)           (None, 28, 28, 1)         1025      \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 28, 28, 1)         0         \n",
      "=================================================================\n",
      "Total params: 1,028,673\n",
      "Trainable params: 1,028,289\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n",
      "0 [D loss: 0.999901] [G loss: 1.000192]\n",
      "1 [D loss: 0.999909] [G loss: 1.000198]\n",
      "2 [D loss: 0.999911] [G loss: 1.000197]\n",
      "3 [D loss: 0.999911] [G loss: 1.000196]\n",
      "4 [D loss: 0.999914] [G loss: 1.000198]\n",
      "5 [D loss: 0.999913] [G loss: 1.000198]\n",
      "6 [D loss: 0.999912] [G loss: 1.000201]\n",
      "7 [D loss: 0.999915] [G loss: 1.000196]\n",
      "8 [D loss: 0.999913] [G loss: 1.000198]\n",
      "9 [D loss: 0.999914] [G loss: 1.000204]\n",
      "10 [D loss: 0.999914] [G loss: 1.000199]\n",
      "11 [D loss: 0.999919] [G loss: 1.000195]\n",
      "12 [D loss: 0.999920] [G loss: 1.000183]\n",
      "13 [D loss: 0.999916] [G loss: 1.000181]\n",
      "14 [D loss: 0.999918] [G loss: 1.000171]\n",
      "15 [D loss: 0.999921] [G loss: 1.000168]\n",
      "16 [D loss: 0.999928] [G loss: 1.000156]\n",
      "17 [D loss: 0.999932] [G loss: 1.000149]\n",
      "18 [D loss: 0.999934] [G loss: 1.000139]\n",
      "19 [D loss: 0.999939] [G loss: 1.000133]\n",
      "20 [D loss: 0.999943] [G loss: 1.000127]\n",
      "21 [D loss: 0.999943] [G loss: 1.000116]\n",
      "22 [D loss: 0.999944] [G loss: 1.000107]\n",
      "23 [D loss: 0.999948] [G loss: 1.000106]\n",
      "24 [D loss: 0.999953] [G loss: 1.000102]\n",
      "25 [D loss: 0.999953] [G loss: 1.000099]\n",
      "26 [D loss: 0.999956] [G loss: 1.000094]\n",
      "27 [D loss: 0.999954] [G loss: 1.000093]\n",
      "28 [D loss: 0.999957] [G loss: 1.000086]\n",
      "29 [D loss: 0.999958] [G loss: 1.000082]\n",
      "30 [D loss: 0.999962] [G loss: 1.000079]\n",
      "31 [D loss: 0.999958] [G loss: 1.000083]\n",
      "32 [D loss: 0.999961] [G loss: 1.000079]\n",
      "33 [D loss: 0.999965] [G loss: 1.000077]\n",
      "34 [D loss: 0.999969] [G loss: 1.000077]\n",
      "35 [D loss: 0.999964] [G loss: 1.000069]\n",
      "36 [D loss: 0.999965] [G loss: 1.000076]\n",
      "37 [D loss: 0.999966] [G loss: 1.000070]\n",
      "38 [D loss: 0.999967] [G loss: 1.000067]\n",
      "39 [D loss: 0.999966] [G loss: 1.000068]\n",
      "40 [D loss: 0.999966] [G loss: 1.000070]\n",
      "41 [D loss: 0.999967] [G loss: 1.000071]\n",
      "42 [D loss: 0.999968] [G loss: 1.000067]\n",
      "43 [D loss: 0.999971] [G loss: 1.000066]\n",
      "44 [D loss: 0.999969] [G loss: 1.000065]\n",
      "45 [D loss: 0.999970] [G loss: 1.000067]\n",
      "46 [D loss: 0.999970] [G loss: 1.000066]\n",
      "47 [D loss: 0.999970] [G loss: 1.000067]\n",
      "48 [D loss: 0.999975] [G loss: 1.000063]\n",
      "49 [D loss: 0.999971] [G loss: 1.000068]\n",
      "50 [D loss: 0.999977] [G loss: 1.000065]\n",
      "51 [D loss: 0.999973] [G loss: 1.000069]\n",
      "52 [D loss: 0.999975] [G loss: 1.000062]\n",
      "53 [D loss: 0.999972] [G loss: 1.000066]\n",
      "54 [D loss: 0.999972] [G loss: 1.000060]\n",
      "55 [D loss: 0.999974] [G loss: 1.000067]\n",
      "56 [D loss: 0.999976] [G loss: 1.000065]\n",
      "57 [D loss: 0.999975] [G loss: 1.000070]\n",
      "58 [D loss: 0.999978] [G loss: 1.000059]\n",
      "59 [D loss: 0.999981] [G loss: 1.000063]\n",
      "60 [D loss: 0.999976] [G loss: 1.000066]\n",
      "61 [D loss: 0.999985] [G loss: 1.000065]\n",
      "62 [D loss: 0.999978] [G loss: 1.000068]\n",
      "63 [D loss: 0.999980] [G loss: 1.000061]\n",
      "64 [D loss: 0.999984] [G loss: 1.000061]\n",
      "65 [D loss: 0.999980] [G loss: 1.000069]\n",
      "66 [D loss: 0.999981] [G loss: 1.000063]\n",
      "67 [D loss: 0.999983] [G loss: 1.000069]\n",
      "68 [D loss: 0.999983] [G loss: 1.000066]\n",
      "69 [D loss: 0.999981] [G loss: 1.000078]\n",
      "70 [D loss: 0.999980] [G loss: 1.000069]\n",
      "71 [D loss: 0.999984] [G loss: 1.000076]\n",
      "72 [D loss: 0.999976] [G loss: 1.000080]\n",
      "73 [D loss: 0.999982] [G loss: 1.000081]\n",
      "74 [D loss: 0.999980] [G loss: 1.000084]\n",
      "75 [D loss: 0.999985] [G loss: 1.000087]\n",
      "76 [D loss: 0.999982] [G loss: 1.000096]\n",
      "77 [D loss: 0.999980] [G loss: 1.000092]\n",
      "78 [D loss: 0.999980] [G loss: 1.000096]\n",
      "79 [D loss: 0.999976] [G loss: 1.000103]\n",
      "80 [D loss: 0.999978] [G loss: 1.000102]\n",
      "81 [D loss: 0.999977] [G loss: 1.000098]\n",
      "82 [D loss: 0.999976] [G loss: 1.000111]\n",
      "83 [D loss: 0.999978] [G loss: 1.000103]\n",
      "84 [D loss: 0.999976] [G loss: 1.000108]\n",
      "85 [D loss: 0.999977] [G loss: 1.000114]\n",
      "86 [D loss: 0.999976] [G loss: 1.000109]\n",
      "87 [D loss: 0.999975] [G loss: 1.000104]\n",
      "88 [D loss: 0.999974] [G loss: 1.000116]\n",
      "89 [D loss: 0.999972] [G loss: 1.000118]\n",
      "90 [D loss: 0.999973] [G loss: 1.000112]\n",
      "91 [D loss: 0.999969] [G loss: 1.000116]\n",
      "92 [D loss: 0.999972] [G loss: 1.000115]\n",
      "93 [D loss: 0.999977] [G loss: 1.000113]\n",
      "94 [D loss: 0.999971] [G loss: 1.000111]\n",
      "95 [D loss: 0.999974] [G loss: 1.000114]\n",
      "96 [D loss: 0.999970] [G loss: 1.000114]\n",
      "97 [D loss: 0.999970] [G loss: 1.000111]\n",
      "98 [D loss: 0.999970] [G loss: 1.000112]\n",
      "99 [D loss: 0.999971] [G loss: 1.000109]\n",
      "100 [D loss: 0.999971] [G loss: 1.000109]\n",
      "101 [D loss: 0.999971] [G loss: 1.000107]\n",
      "102 [D loss: 0.999967] [G loss: 1.000107]\n",
      "103 [D loss: 0.999970] [G loss: 1.000106]\n",
      "104 [D loss: 0.999966] [G loss: 1.000114]\n",
      "105 [D loss: 0.999965] [G loss: 1.000107]\n",
      "106 [D loss: 0.999972] [G loss: 1.000109]\n",
      "107 [D loss: 0.999973] [G loss: 1.000099]\n",
      "108 [D loss: 0.999968] [G loss: 1.000102]\n",
      "109 [D loss: 0.999973] [G loss: 1.000092]\n",
      "110 [D loss: 0.999964] [G loss: 1.000101]\n",
      "111 [D loss: 0.999970] [G loss: 1.000091]\n",
      "112 [D loss: 0.999970] [G loss: 1.000093]\n",
      "113 [D loss: 0.999969] [G loss: 1.000086]\n",
      "114 [D loss: 0.999971] [G loss: 1.000090]\n",
      "115 [D loss: 0.999972] [G loss: 1.000091]\n",
      "116 [D loss: 0.999969] [G loss: 1.000089]\n",
      "117 [D loss: 0.999970] [G loss: 1.000086]\n",
      "118 [D loss: 0.999971] [G loss: 1.000083]\n",
      "119 [D loss: 0.999969] [G loss: 1.000084]\n",
      "120 [D loss: 0.999972] [G loss: 1.000085]\n",
      "121 [D loss: 0.999969] [G loss: 1.000081]\n",
      "122 [D loss: 0.999972] [G loss: 1.000081]\n",
      "123 [D loss: 0.999974] [G loss: 1.000089]\n",
      "124 [D loss: 0.999968] [G loss: 1.000084]\n",
      "125 [D loss: 0.999971] [G loss: 1.000077]\n",
      "126 [D loss: 0.999967] [G loss: 1.000084]\n",
      "127 [D loss: 0.999973] [G loss: 1.000083]\n",
      "128 [D loss: 0.999968] [G loss: 1.000080]\n",
      "129 [D loss: 0.999968] [G loss: 1.000073]\n",
      "130 [D loss: 0.999972] [G loss: 1.000073]\n",
      "131 [D loss: 0.999970] [G loss: 1.000073]\n",
      "132 [D loss: 0.999971] [G loss: 1.000074]\n",
      "133 [D loss: 0.999972] [G loss: 1.000071]\n",
      "134 [D loss: 0.999972] [G loss: 1.000073]\n",
      "135 [D loss: 0.999971] [G loss: 1.000076]\n",
      "136 [D loss: 0.999973] [G loss: 1.000072]\n",
      "137 [D loss: 0.999973] [G loss: 1.000068]\n",
      "138 [D loss: 0.999969] [G loss: 1.000069]\n",
      "139 [D loss: 0.999974] [G loss: 1.000072]\n",
      "140 [D loss: 0.999971] [G loss: 1.000062]\n",
      "141 [D loss: 0.999972] [G loss: 1.000067]\n",
      "142 [D loss: 0.999970] [G loss: 1.000071]\n",
      "143 [D loss: 0.999970] [G loss: 1.000073]\n",
      "144 [D loss: 0.999975] [G loss: 1.000070]\n",
      "145 [D loss: 0.999969] [G loss: 1.000067]\n",
      "146 [D loss: 0.999975] [G loss: 1.000071]\n",
      "147 [D loss: 0.999971] [G loss: 1.000068]\n",
      "148 [D loss: 0.999973] [G loss: 1.000068]\n",
      "149 [D loss: 0.999974] [G loss: 1.000065]\n",
      "150 [D loss: 0.999971] [G loss: 1.000071]\n",
      "151 [D loss: 0.999975] [G loss: 1.000068]\n",
      "152 [D loss: 0.999972] [G loss: 1.000064]\n",
      "153 [D loss: 0.999971] [G loss: 1.000074]\n",
      "154 [D loss: 0.999971] [G loss: 1.000073]\n",
      "155 [D loss: 0.999971] [G loss: 1.000072]\n",
      "156 [D loss: 0.999969] [G loss: 1.000065]\n",
      "157 [D loss: 0.999971] [G loss: 1.000070]\n",
      "158 [D loss: 0.999972] [G loss: 1.000066]\n",
      "159 [D loss: 0.999972] [G loss: 1.000068]\n",
      "160 [D loss: 0.999972] [G loss: 1.000070]\n",
      "161 [D loss: 0.999974] [G loss: 1.000060]\n",
      "162 [D loss: 0.999977] [G loss: 1.000068]\n",
      "163 [D loss: 0.999973] [G loss: 1.000069]\n",
      "164 [D loss: 0.999971] [G loss: 1.000067]\n",
      "165 [D loss: 0.999975] [G loss: 1.000066]\n",
      "166 [D loss: 0.999969] [G loss: 1.000063]\n",
      "167 [D loss: 0.999976] [G loss: 1.000064]\n",
      "168 [D loss: 0.999975] [G loss: 1.000060]\n",
      "169 [D loss: 0.999973] [G loss: 1.000073]\n",
      "170 [D loss: 0.999975] [G loss: 1.000064]\n",
      "171 [D loss: 0.999979] [G loss: 1.000068]\n",
      "172 [D loss: 0.999969] [G loss: 1.000077]\n",
      "173 [D loss: 0.999969] [G loss: 1.000069]\n",
      "174 [D loss: 0.999980] [G loss: 1.000066]\n",
      "175 [D loss: 0.999972] [G loss: 1.000071]\n",
      "176 [D loss: 0.999969] [G loss: 1.000067]\n",
      "177 [D loss: 0.999970] [G loss: 1.000070]\n",
      "178 [D loss: 0.999970] [G loss: 1.000071]\n",
      "179 [D loss: 0.999971] [G loss: 1.000066]\n",
      "180 [D loss: 0.999977] [G loss: 1.000070]\n",
      "181 [D loss: 0.999972] [G loss: 1.000069]\n",
      "182 [D loss: 0.999969] [G loss: 1.000075]\n",
      "183 [D loss: 0.999972] [G loss: 1.000074]\n",
      "184 [D loss: 0.999972] [G loss: 1.000070]\n",
      "185 [D loss: 0.999970] [G loss: 1.000070]\n",
      "186 [D loss: 0.999968] [G loss: 1.000068]\n",
      "187 [D loss: 0.999972] [G loss: 1.000071]\n",
      "188 [D loss: 0.999974] [G loss: 1.000078]\n",
      "189 [D loss: 0.999971] [G loss: 1.000074]\n",
      "190 [D loss: 0.999967] [G loss: 1.000067]\n",
      "191 [D loss: 0.999977] [G loss: 1.000074]\n",
      "192 [D loss: 0.999972] [G loss: 1.000073]\n",
      "193 [D loss: 0.999976] [G loss: 1.000067]\n",
      "194 [D loss: 0.999970] [G loss: 1.000069]\n",
      "195 [D loss: 0.999971] [G loss: 1.000064]\n",
      "196 [D loss: 0.999975] [G loss: 1.000065]\n",
      "197 [D loss: 0.999970] [G loss: 1.000077]\n",
      "198 [D loss: 0.999967] [G loss: 1.000075]\n",
      "199 [D loss: 0.999971] [G loss: 1.000069]\n",
      "200 [D loss: 0.999972] [G loss: 1.000066]\n",
      "201 [D loss: 0.999967] [G loss: 1.000062]\n",
      "202 [D loss: 0.999970] [G loss: 1.000070]\n",
      "203 [D loss: 0.999973] [G loss: 1.000068]\n",
      "204 [D loss: 0.999968] [G loss: 1.000072]\n",
      "205 [D loss: 0.999968] [G loss: 1.000074]\n",
      "206 [D loss: 0.999969] [G loss: 1.000070]\n",
      "207 [D loss: 0.999975] [G loss: 1.000067]\n",
      "208 [D loss: 0.999972] [G loss: 1.000073]\n",
      "209 [D loss: 0.999973] [G loss: 1.000068]\n",
      "210 [D loss: 0.999971] [G loss: 1.000075]\n",
      "211 [D loss: 0.999970] [G loss: 1.000075]\n",
      "212 [D loss: 0.999971] [G loss: 1.000072]\n",
      "213 [D loss: 0.999973] [G loss: 1.000063]\n",
      "214 [D loss: 0.999965] [G loss: 1.000072]\n",
      "215 [D loss: 0.999972] [G loss: 1.000075]\n",
      "216 [D loss: 0.999972] [G loss: 1.000062]\n",
      "217 [D loss: 0.999971] [G loss: 1.000075]\n",
      "218 [D loss: 0.999968] [G loss: 1.000071]\n",
      "219 [D loss: 0.999970] [G loss: 1.000072]\n",
      "220 [D loss: 0.999969] [G loss: 1.000073]\n",
      "221 [D loss: 0.999966] [G loss: 1.000068]\n",
      "222 [D loss: 0.999971] [G loss: 1.000072]\n",
      "223 [D loss: 0.999970] [G loss: 1.000071]\n",
      "224 [D loss: 0.999968] [G loss: 1.000070]\n",
      "225 [D loss: 0.999975] [G loss: 1.000069]\n",
      "226 [D loss: 0.999974] [G loss: 1.000074]\n",
      "227 [D loss: 0.999970] [G loss: 1.000071]\n",
      "228 [D loss: 0.999971] [G loss: 1.000072]\n",
      "229 [D loss: 0.999970] [G loss: 1.000075]\n",
      "230 [D loss: 0.999973] [G loss: 1.000074]\n",
      "231 [D loss: 0.999972] [G loss: 1.000072]\n",
      "232 [D loss: 0.999970] [G loss: 1.000071]\n",
      "233 [D loss: 0.999970] [G loss: 1.000072]\n",
      "234 [D loss: 0.999970] [G loss: 1.000074]\n",
      "235 [D loss: 0.999972] [G loss: 1.000071]\n",
      "236 [D loss: 0.999974] [G loss: 1.000073]\n",
      "237 [D loss: 0.999972] [G loss: 1.000074]\n",
      "238 [D loss: 0.999974] [G loss: 1.000070]\n",
      "239 [D loss: 0.999968] [G loss: 1.000073]\n",
      "240 [D loss: 0.999971] [G loss: 1.000063]\n",
      "241 [D loss: 0.999972] [G loss: 1.000073]\n",
      "242 [D loss: 0.999974] [G loss: 1.000071]\n",
      "243 [D loss: 0.999972] [G loss: 1.000075]\n",
      "244 [D loss: 0.999971] [G loss: 1.000068]\n",
      "245 [D loss: 0.999974] [G loss: 1.000067]\n",
      "246 [D loss: 0.999967] [G loss: 1.000071]\n",
      "247 [D loss: 0.999968] [G loss: 1.000070]\n",
      "248 [D loss: 0.999974] [G loss: 1.000071]\n",
      "249 [D loss: 0.999969] [G loss: 1.000070]\n",
      "250 [D loss: 0.999971] [G loss: 1.000070]\n",
      "251 [D loss: 0.999970] [G loss: 1.000069]\n",
      "252 [D loss: 0.999972] [G loss: 1.000076]\n",
      "253 [D loss: 0.999971] [G loss: 1.000067]\n",
      "254 [D loss: 0.999968] [G loss: 1.000075]\n",
      "255 [D loss: 0.999973] [G loss: 1.000070]\n",
      "256 [D loss: 0.999972] [G loss: 1.000071]\n",
      "257 [D loss: 0.999969] [G loss: 1.000061]\n",
      "258 [D loss: 0.999976] [G loss: 1.000071]\n",
      "259 [D loss: 0.999969] [G loss: 1.000075]\n",
      "260 [D loss: 0.999973] [G loss: 1.000072]\n",
      "261 [D loss: 0.999972] [G loss: 1.000071]\n",
      "262 [D loss: 0.999968] [G loss: 1.000071]\n",
      "263 [D loss: 0.999972] [G loss: 1.000067]\n",
      "264 [D loss: 0.999974] [G loss: 1.000068]\n",
      "265 [D loss: 0.999972] [G loss: 1.000067]\n",
      "266 [D loss: 0.999971] [G loss: 1.000069]\n",
      "267 [D loss: 0.999972] [G loss: 1.000068]\n",
      "268 [D loss: 0.999970] [G loss: 1.000070]\n",
      "269 [D loss: 0.999971] [G loss: 1.000069]\n",
      "270 [D loss: 0.999972] [G loss: 1.000067]\n",
      "271 [D loss: 0.999967] [G loss: 1.000068]\n",
      "272 [D loss: 0.999967] [G loss: 1.000068]\n",
      "273 [D loss: 0.999972] [G loss: 1.000066]\n",
      "274 [D loss: 0.999964] [G loss: 1.000065]\n",
      "275 [D loss: 0.999972] [G loss: 1.000068]\n",
      "276 [D loss: 0.999972] [G loss: 1.000068]\n",
      "277 [D loss: 0.999973] [G loss: 1.000069]\n",
      "278 [D loss: 0.999969] [G loss: 1.000065]\n",
      "279 [D loss: 0.999972] [G loss: 1.000067]\n",
      "280 [D loss: 0.999971] [G loss: 1.000066]\n",
      "281 [D loss: 0.999975] [G loss: 1.000068]\n",
      "282 [D loss: 0.999972] [G loss: 1.000068]\n",
      "283 [D loss: 0.999973] [G loss: 1.000072]\n",
      "284 [D loss: 0.999974] [G loss: 1.000066]\n",
      "285 [D loss: 0.999974] [G loss: 1.000068]\n",
      "286 [D loss: 0.999973] [G loss: 1.000066]\n",
      "287 [D loss: 0.999974] [G loss: 1.000066]\n",
      "288 [D loss: 0.999971] [G loss: 1.000064]\n",
      "289 [D loss: 0.999970] [G loss: 1.000066]\n",
      "290 [D loss: 0.999972] [G loss: 1.000067]\n",
      "291 [D loss: 0.999968] [G loss: 1.000067]\n",
      "292 [D loss: 0.999972] [G loss: 1.000065]\n",
      "293 [D loss: 0.999974] [G loss: 1.000069]\n",
      "294 [D loss: 0.999972] [G loss: 1.000068]\n",
      "295 [D loss: 0.999971] [G loss: 1.000067]\n",
      "296 [D loss: 0.999970] [G loss: 1.000069]\n",
      "297 [D loss: 0.999965] [G loss: 1.000067]\n",
      "298 [D loss: 0.999969] [G loss: 1.000068]\n",
      "299 [D loss: 0.999972] [G loss: 1.000072]\n",
      "300 [D loss: 0.999970] [G loss: 1.000068]\n",
      "301 [D loss: 0.999974] [G loss: 1.000066]\n",
      "302 [D loss: 0.999969] [G loss: 1.000066]\n",
      "303 [D loss: 0.999970] [G loss: 1.000066]\n",
      "304 [D loss: 0.999971] [G loss: 1.000068]\n",
      "305 [D loss: 0.999969] [G loss: 1.000071]\n",
      "306 [D loss: 0.999974] [G loss: 1.000056]\n",
      "307 [D loss: 0.999972] [G loss: 1.000067]\n",
      "308 [D loss: 0.999972] [G loss: 1.000073]\n",
      "309 [D loss: 0.999974] [G loss: 1.000065]\n",
      "310 [D loss: 0.999973] [G loss: 1.000068]\n",
      "311 [D loss: 0.999972] [G loss: 1.000067]\n",
      "312 [D loss: 0.999969] [G loss: 1.000065]\n",
      "313 [D loss: 0.999968] [G loss: 1.000067]\n",
      "314 [D loss: 0.999971] [G loss: 1.000071]\n",
      "315 [D loss: 0.999972] [G loss: 1.000064]\n",
      "316 [D loss: 0.999974] [G loss: 1.000067]\n",
      "317 [D loss: 0.999967] [G loss: 1.000064]\n",
      "318 [D loss: 0.999974] [G loss: 1.000073]\n",
      "319 [D loss: 0.999969] [G loss: 1.000070]\n",
      "320 [D loss: 0.999970] [G loss: 1.000063]\n",
      "321 [D loss: 0.999973] [G loss: 1.000071]\n",
      "322 [D loss: 0.999972] [G loss: 1.000064]\n",
      "323 [D loss: 0.999972] [G loss: 1.000060]\n",
      "324 [D loss: 0.999969] [G loss: 1.000067]\n",
      "325 [D loss: 0.999970] [G loss: 1.000067]\n",
      "326 [D loss: 0.999975] [G loss: 1.000069]\n",
      "327 [D loss: 0.999974] [G loss: 1.000068]\n",
      "328 [D loss: 0.999968] [G loss: 1.000061]\n",
      "329 [D loss: 0.999974] [G loss: 1.000066]\n",
      "330 [D loss: 0.999974] [G loss: 1.000065]\n",
      "331 [D loss: 0.999977] [G loss: 1.000061]\n",
      "332 [D loss: 0.999977] [G loss: 1.000070]\n",
      "333 [D loss: 0.999974] [G loss: 1.000067]\n",
      "334 [D loss: 0.999974] [G loss: 1.000061]\n",
      "335 [D loss: 0.999967] [G loss: 1.000067]\n",
      "336 [D loss: 0.999966] [G loss: 1.000057]\n",
      "337 [D loss: 0.999967] [G loss: 1.000069]\n",
      "338 [D loss: 0.999972] [G loss: 1.000062]\n",
      "339 [D loss: 0.999974] [G loss: 1.000057]\n",
      "340 [D loss: 0.999970] [G loss: 1.000061]\n",
      "341 [D loss: 0.999976] [G loss: 1.000062]\n",
      "342 [D loss: 0.999968] [G loss: 1.000065]\n",
      "343 [D loss: 0.999967] [G loss: 1.000058]\n",
      "344 [D loss: 0.999973] [G loss: 1.000066]\n",
      "345 [D loss: 0.999972] [G loss: 1.000069]\n",
      "346 [D loss: 0.999974] [G loss: 1.000063]\n",
      "347 [D loss: 0.999973] [G loss: 1.000066]\n",
      "348 [D loss: 0.999973] [G loss: 1.000066]\n",
      "349 [D loss: 0.999972] [G loss: 1.000064]\n",
      "350 [D loss: 0.999975] [G loss: 1.000063]\n",
      "351 [D loss: 0.999966] [G loss: 1.000062]\n",
      "352 [D loss: 0.999968] [G loss: 1.000067]\n",
      "353 [D loss: 0.999972] [G loss: 1.000063]\n",
      "354 [D loss: 0.999972] [G loss: 1.000067]\n",
      "355 [D loss: 0.999969] [G loss: 1.000068]\n",
      "356 [D loss: 0.999972] [G loss: 1.000063]\n",
      "357 [D loss: 0.999975] [G loss: 1.000059]\n",
      "358 [D loss: 0.999969] [G loss: 1.000070]\n",
      "359 [D loss: 0.999974] [G loss: 1.000064]\n",
      "360 [D loss: 0.999968] [G loss: 1.000066]\n",
      "361 [D loss: 0.999972] [G loss: 1.000063]\n",
      "362 [D loss: 0.999967] [G loss: 1.000073]\n",
      "363 [D loss: 0.999972] [G loss: 1.000064]\n",
      "364 [D loss: 0.999974] [G loss: 1.000064]\n",
      "365 [D loss: 0.999972] [G loss: 1.000067]\n",
      "366 [D loss: 0.999971] [G loss: 1.000063]\n",
      "367 [D loss: 0.999972] [G loss: 1.000064]\n",
      "368 [D loss: 0.999973] [G loss: 1.000059]\n",
      "369 [D loss: 0.999972] [G loss: 1.000066]\n",
      "370 [D loss: 0.999972] [G loss: 1.000066]\n",
      "371 [D loss: 0.999971] [G loss: 1.000065]\n",
      "372 [D loss: 0.999971] [G loss: 1.000071]\n",
      "373 [D loss: 0.999971] [G loss: 1.000068]\n",
      "374 [D loss: 0.999972] [G loss: 1.000067]\n",
      "375 [D loss: 0.999971] [G loss: 1.000069]\n",
      "376 [D loss: 0.999973] [G loss: 1.000065]\n",
      "377 [D loss: 0.999972] [G loss: 1.000070]\n",
      "378 [D loss: 0.999971] [G loss: 1.000070]\n",
      "379 [D loss: 0.999974] [G loss: 1.000066]\n",
      "380 [D loss: 0.999973] [G loss: 1.000070]\n",
      "381 [D loss: 0.999978] [G loss: 1.000069]\n",
      "382 [D loss: 0.999972] [G loss: 1.000065]\n",
      "383 [D loss: 0.999973] [G loss: 1.000067]\n",
      "384 [D loss: 0.999973] [G loss: 1.000067]\n",
      "385 [D loss: 0.999971] [G loss: 1.000067]\n",
      "386 [D loss: 0.999969] [G loss: 1.000069]\n",
      "387 [D loss: 0.999974] [G loss: 1.000068]\n",
      "388 [D loss: 0.999968] [G loss: 1.000067]\n",
      "389 [D loss: 0.999970] [G loss: 1.000063]\n",
      "390 [D loss: 0.999972] [G loss: 1.000061]\n",
      "391 [D loss: 0.999972] [G loss: 1.000065]\n",
      "392 [D loss: 0.999974] [G loss: 1.000067]\n",
      "393 [D loss: 0.999974] [G loss: 1.000062]\n",
      "394 [D loss: 0.999972] [G loss: 1.000067]\n",
      "395 [D loss: 0.999973] [G loss: 1.000068]\n",
      "396 [D loss: 0.999970] [G loss: 1.000070]\n",
      "397 [D loss: 0.999972] [G loss: 1.000068]\n",
      "398 [D loss: 0.999972] [G loss: 1.000067]\n",
      "399 [D loss: 0.999971] [G loss: 1.000067]\n",
      "400 [D loss: 0.999972] [G loss: 1.000066]\n",
      "401 [D loss: 0.999970] [G loss: 1.000066]\n",
      "402 [D loss: 0.999975] [G loss: 1.000064]\n",
      "403 [D loss: 0.999969] [G loss: 1.000062]\n",
      "404 [D loss: 0.999974] [G loss: 1.000067]\n",
      "405 [D loss: 0.999972] [G loss: 1.000065]\n",
      "406 [D loss: 0.999973] [G loss: 1.000067]\n",
      "407 [D loss: 0.999972] [G loss: 1.000067]\n",
      "408 [D loss: 0.999970] [G loss: 1.000064]\n",
      "409 [D loss: 0.999971] [G loss: 1.000065]\n",
      "410 [D loss: 0.999972] [G loss: 1.000067]\n",
      "411 [D loss: 0.999972] [G loss: 1.000068]\n",
      "412 [D loss: 0.999972] [G loss: 1.000061]\n",
      "413 [D loss: 0.999970] [G loss: 1.000059]\n",
      "414 [D loss: 0.999971] [G loss: 1.000065]\n",
      "415 [D loss: 0.999971] [G loss: 1.000066]\n",
      "416 [D loss: 0.999973] [G loss: 1.000059]\n",
      "417 [D loss: 0.999973] [G loss: 1.000070]\n",
      "418 [D loss: 0.999970] [G loss: 1.000069]\n",
      "419 [D loss: 0.999969] [G loss: 1.000063]\n",
      "420 [D loss: 0.999972] [G loss: 1.000068]\n",
      "421 [D loss: 0.999973] [G loss: 1.000063]\n",
      "422 [D loss: 0.999969] [G loss: 1.000070]\n",
      "423 [D loss: 0.999970] [G loss: 1.000065]\n",
      "424 [D loss: 0.999974] [G loss: 1.000061]\n",
      "425 [D loss: 0.999971] [G loss: 1.000068]\n",
      "426 [D loss: 0.999972] [G loss: 1.000062]\n",
      "427 [D loss: 0.999970] [G loss: 1.000066]\n",
      "428 [D loss: 0.999972] [G loss: 1.000063]\n",
      "429 [D loss: 0.999970] [G loss: 1.000068]\n",
      "430 [D loss: 0.999972] [G loss: 1.000066]\n",
      "431 [D loss: 0.999974] [G loss: 1.000070]\n",
      "432 [D loss: 0.999969] [G loss: 1.000063]\n",
      "433 [D loss: 0.999973] [G loss: 1.000060]\n",
      "434 [D loss: 0.999974] [G loss: 1.000064]\n",
      "435 [D loss: 0.999972] [G loss: 1.000065]\n",
      "436 [D loss: 0.999975] [G loss: 1.000061]\n",
      "437 [D loss: 0.999972] [G loss: 1.000065]\n",
      "438 [D loss: 0.999972] [G loss: 1.000063]\n",
      "439 [D loss: 0.999970] [G loss: 1.000069]\n",
      "440 [D loss: 0.999971] [G loss: 1.000063]\n",
      "441 [D loss: 0.999971] [G loss: 1.000066]\n",
      "442 [D loss: 0.999969] [G loss: 1.000067]\n",
      "443 [D loss: 0.999975] [G loss: 1.000063]\n",
      "444 [D loss: 0.999973] [G loss: 1.000064]\n",
      "445 [D loss: 0.999971] [G loss: 1.000061]\n",
      "446 [D loss: 0.999973] [G loss: 1.000065]\n",
      "447 [D loss: 0.999973] [G loss: 1.000067]\n",
      "448 [D loss: 0.999976] [G loss: 1.000066]\n",
      "449 [D loss: 0.999973] [G loss: 1.000064]\n",
      "450 [D loss: 0.999968] [G loss: 1.000062]\n",
      "451 [D loss: 0.999968] [G loss: 1.000063]\n",
      "452 [D loss: 0.999975] [G loss: 1.000068]\n",
      "453 [D loss: 0.999966] [G loss: 1.000065]\n",
      "454 [D loss: 0.999971] [G loss: 1.000067]\n",
      "455 [D loss: 0.999970] [G loss: 1.000069]\n",
      "456 [D loss: 0.999973] [G loss: 1.000063]\n",
      "457 [D loss: 0.999970] [G loss: 1.000067]\n",
      "458 [D loss: 0.999971] [G loss: 1.000064]\n",
      "459 [D loss: 0.999971] [G loss: 1.000065]\n",
      "460 [D loss: 0.999972] [G loss: 1.000068]\n",
      "461 [D loss: 0.999972] [G loss: 1.000068]\n",
      "462 [D loss: 0.999974] [G loss: 1.000071]\n",
      "463 [D loss: 0.999971] [G loss: 1.000060]\n",
      "464 [D loss: 0.999974] [G loss: 1.000063]\n",
      "465 [D loss: 0.999970] [G loss: 1.000067]\n",
      "466 [D loss: 0.999974] [G loss: 1.000064]\n",
      "467 [D loss: 0.999972] [G loss: 1.000064]\n",
      "468 [D loss: 0.999972] [G loss: 1.000069]\n",
      "469 [D loss: 0.999975] [G loss: 1.000064]\n",
      "470 [D loss: 0.999972] [G loss: 1.000067]\n",
      "471 [D loss: 0.999973] [G loss: 1.000070]\n",
      "472 [D loss: 0.999974] [G loss: 1.000063]\n",
      "473 [D loss: 0.999969] [G loss: 1.000061]\n",
      "474 [D loss: 0.999970] [G loss: 1.000065]\n",
      "475 [D loss: 0.999970] [G loss: 1.000064]\n",
      "476 [D loss: 0.999972] [G loss: 1.000068]\n",
      "477 [D loss: 0.999970] [G loss: 1.000063]\n",
      "478 [D loss: 0.999972] [G loss: 1.000065]\n",
      "479 [D loss: 0.999976] [G loss: 1.000065]\n",
      "480 [D loss: 0.999971] [G loss: 1.000068]\n",
      "481 [D loss: 0.999973] [G loss: 1.000067]\n",
      "482 [D loss: 0.999974] [G loss: 1.000064]\n",
      "483 [D loss: 0.999975] [G loss: 1.000066]\n",
      "484 [D loss: 0.999970] [G loss: 1.000066]\n",
      "485 [D loss: 0.999970] [G loss: 1.000059]\n",
      "486 [D loss: 0.999974] [G loss: 1.000065]\n",
      "487 [D loss: 0.999970] [G loss: 1.000069]\n",
      "488 [D loss: 0.999972] [G loss: 1.000058]\n",
      "489 [D loss: 0.999973] [G loss: 1.000066]\n",
      "490 [D loss: 0.999974] [G loss: 1.000067]\n",
      "491 [D loss: 0.999975] [G loss: 1.000071]\n",
      "492 [D loss: 0.999969] [G loss: 1.000064]\n",
      "493 [D loss: 0.999973] [G loss: 1.000071]\n",
      "494 [D loss: 0.999969] [G loss: 1.000065]\n",
      "495 [D loss: 0.999973] [G loss: 1.000063]\n",
      "496 [D loss: 0.999974] [G loss: 1.000060]\n",
      "497 [D loss: 0.999973] [G loss: 1.000065]\n",
      "498 [D loss: 0.999977] [G loss: 1.000067]\n",
      "499 [D loss: 0.999968] [G loss: 1.000065]\n",
      "500 [D loss: 0.999970] [G loss: 1.000070]\n",
      "501 [D loss: 0.999970] [G loss: 1.000070]\n",
      "502 [D loss: 0.999971] [G loss: 1.000066]\n",
      "503 [D loss: 0.999970] [G loss: 1.000067]\n",
      "504 [D loss: 0.999971] [G loss: 1.000070]\n",
      "505 [D loss: 0.999974] [G loss: 1.000067]\n",
      "506 [D loss: 0.999972] [G loss: 1.000065]\n",
      "507 [D loss: 0.999972] [G loss: 1.000067]\n",
      "508 [D loss: 0.999972] [G loss: 1.000069]\n",
      "509 [D loss: 0.999973] [G loss: 1.000068]\n",
      "510 [D loss: 0.999969] [G loss: 1.000069]\n",
      "511 [D loss: 0.999971] [G loss: 1.000067]\n",
      "512 [D loss: 0.999973] [G loss: 1.000070]\n",
      "513 [D loss: 0.999972] [G loss: 1.000061]\n",
      "514 [D loss: 0.999971] [G loss: 1.000066]\n",
      "515 [D loss: 0.999972] [G loss: 1.000064]\n",
      "516 [D loss: 0.999972] [G loss: 1.000066]\n",
      "517 [D loss: 0.999970] [G loss: 1.000072]\n",
      "518 [D loss: 0.999973] [G loss: 1.000066]\n",
      "519 [D loss: 0.999974] [G loss: 1.000070]\n",
      "520 [D loss: 0.999968] [G loss: 1.000069]\n",
      "521 [D loss: 0.999970] [G loss: 1.000068]\n",
      "522 [D loss: 0.999972] [G loss: 1.000064]\n",
      "523 [D loss: 0.999970] [G loss: 1.000069]\n",
      "524 [D loss: 0.999971] [G loss: 1.000065]\n",
      "525 [D loss: 0.999974] [G loss: 1.000070]\n",
      "526 [D loss: 0.999975] [G loss: 1.000066]\n",
      "527 [D loss: 0.999971] [G loss: 1.000065]\n",
      "528 [D loss: 0.999972] [G loss: 1.000063]\n",
      "529 [D loss: 0.999971] [G loss: 1.000063]\n",
      "530 [D loss: 0.999973] [G loss: 1.000074]\n",
      "531 [D loss: 0.999972] [G loss: 1.000071]\n",
      "532 [D loss: 0.999972] [G loss: 1.000063]\n",
      "533 [D loss: 0.999971] [G loss: 1.000065]\n",
      "534 [D loss: 0.999972] [G loss: 1.000070]\n",
      "535 [D loss: 0.999968] [G loss: 1.000065]\n",
      "536 [D loss: 0.999975] [G loss: 1.000063]\n",
      "537 [D loss: 0.999972] [G loss: 1.000069]\n",
      "538 [D loss: 0.999973] [G loss: 1.000063]\n",
      "539 [D loss: 0.999977] [G loss: 1.000069]\n",
      "540 [D loss: 0.999972] [G loss: 1.000064]\n",
      "541 [D loss: 0.999972] [G loss: 1.000066]\n",
      "542 [D loss: 0.999966] [G loss: 1.000064]\n",
      "543 [D loss: 0.999969] [G loss: 1.000069]\n",
      "544 [D loss: 0.999972] [G loss: 1.000069]\n",
      "545 [D loss: 0.999972] [G loss: 1.000068]\n",
      "546 [D loss: 0.999971] [G loss: 1.000063]\n",
      "547 [D loss: 0.999972] [G loss: 1.000072]\n",
      "548 [D loss: 0.999966] [G loss: 1.000069]\n",
      "549 [D loss: 0.999972] [G loss: 1.000070]\n",
      "550 [D loss: 0.999971] [G loss: 1.000069]\n",
      "551 [D loss: 0.999972] [G loss: 1.000070]\n",
      "552 [D loss: 0.999973] [G loss: 1.000070]\n",
      "553 [D loss: 0.999970] [G loss: 1.000068]\n",
      "554 [D loss: 0.999973] [G loss: 1.000063]\n",
      "555 [D loss: 0.999970] [G loss: 1.000073]\n",
      "556 [D loss: 0.999969] [G loss: 1.000065]\n",
      "557 [D loss: 0.999970] [G loss: 1.000065]\n",
      "558 [D loss: 0.999972] [G loss: 1.000073]\n",
      "559 [D loss: 0.999971] [G loss: 1.000063]\n",
      "560 [D loss: 0.999974] [G loss: 1.000071]\n",
      "561 [D loss: 0.999972] [G loss: 1.000065]\n",
      "562 [D loss: 0.999971] [G loss: 1.000058]\n",
      "563 [D loss: 0.999973] [G loss: 1.000069]\n",
      "564 [D loss: 0.999971] [G loss: 1.000067]\n",
      "565 [D loss: 0.999971] [G loss: 1.000072]\n",
      "566 [D loss: 0.999977] [G loss: 1.000065]\n",
      "567 [D loss: 0.999968] [G loss: 1.000063]\n",
      "568 [D loss: 0.999965] [G loss: 1.000068]\n",
      "569 [D loss: 0.999971] [G loss: 1.000069]\n",
      "570 [D loss: 0.999967] [G loss: 1.000068]\n",
      "571 [D loss: 0.999971] [G loss: 1.000072]\n",
      "572 [D loss: 0.999967] [G loss: 1.000068]\n",
      "573 [D loss: 0.999974] [G loss: 1.000076]\n",
      "574 [D loss: 0.999974] [G loss: 1.000068]\n",
      "575 [D loss: 0.999967] [G loss: 1.000070]\n",
      "576 [D loss: 0.999972] [G loss: 1.000073]\n",
      "577 [D loss: 0.999970] [G loss: 1.000073]\n",
      "578 [D loss: 0.999969] [G loss: 1.000065]\n",
      "579 [D loss: 0.999970] [G loss: 1.000068]\n",
      "580 [D loss: 0.999972] [G loss: 1.000067]\n",
      "581 [D loss: 0.999974] [G loss: 1.000071]\n",
      "582 [D loss: 0.999967] [G loss: 1.000069]\n",
      "583 [D loss: 0.999968] [G loss: 1.000067]\n",
      "584 [D loss: 0.999969] [G loss: 1.000068]\n",
      "585 [D loss: 0.999965] [G loss: 1.000064]\n",
      "586 [D loss: 0.999976] [G loss: 1.000065]\n",
      "587 [D loss: 0.999967] [G loss: 1.000072]\n",
      "588 [D loss: 0.999967] [G loss: 1.000070]\n",
      "589 [D loss: 0.999972] [G loss: 1.000063]\n",
      "590 [D loss: 0.999973] [G loss: 1.000066]\n",
      "591 [D loss: 0.999970] [G loss: 1.000071]\n",
      "592 [D loss: 0.999968] [G loss: 1.000065]\n",
      "593 [D loss: 0.999973] [G loss: 1.000065]\n",
      "594 [D loss: 0.999972] [G loss: 1.000062]\n",
      "595 [D loss: 0.999972] [G loss: 1.000061]\n",
      "596 [D loss: 0.999972] [G loss: 1.000063]\n",
      "597 [D loss: 0.999972] [G loss: 1.000063]\n",
      "598 [D loss: 0.999976] [G loss: 1.000067]\n",
      "599 [D loss: 0.999973] [G loss: 1.000067]\n",
      "600 [D loss: 0.999971] [G loss: 1.000066]\n",
      "601 [D loss: 0.999969] [G loss: 1.000063]\n",
      "602 [D loss: 0.999973] [G loss: 1.000064]\n",
      "603 [D loss: 0.999973] [G loss: 1.000070]\n",
      "604 [D loss: 0.999972] [G loss: 1.000070]\n",
      "605 [D loss: 0.999966] [G loss: 1.000071]\n",
      "606 [D loss: 0.999976] [G loss: 1.000067]\n",
      "607 [D loss: 0.999972] [G loss: 1.000071]\n",
      "608 [D loss: 0.999971] [G loss: 1.000069]\n",
      "609 [D loss: 0.999971] [G loss: 1.000076]\n",
      "610 [D loss: 0.999972] [G loss: 1.000070]\n",
      "611 [D loss: 0.999972] [G loss: 1.000069]\n",
      "612 [D loss: 0.999970] [G loss: 1.000069]\n",
      "613 [D loss: 0.999976] [G loss: 1.000071]\n",
      "614 [D loss: 0.999968] [G loss: 1.000067]\n",
      "615 [D loss: 0.999971] [G loss: 1.000065]\n",
      "616 [D loss: 0.999972] [G loss: 1.000070]\n",
      "617 [D loss: 0.999972] [G loss: 1.000066]\n",
      "618 [D loss: 0.999968] [G loss: 1.000068]\n",
      "619 [D loss: 0.999973] [G loss: 1.000069]\n",
      "620 [D loss: 0.999972] [G loss: 1.000070]\n",
      "621 [D loss: 0.999975] [G loss: 1.000063]\n",
      "622 [D loss: 0.999973] [G loss: 1.000065]\n",
      "623 [D loss: 0.999973] [G loss: 1.000065]\n",
      "624 [D loss: 0.999972] [G loss: 1.000062]\n",
      "625 [D loss: 0.999976] [G loss: 1.000062]\n",
      "626 [D loss: 0.999975] [G loss: 1.000070]\n",
      "627 [D loss: 0.999973] [G loss: 1.000066]\n",
      "628 [D loss: 0.999974] [G loss: 1.000065]\n",
      "629 [D loss: 0.999974] [G loss: 1.000069]\n",
      "630 [D loss: 0.999974] [G loss: 1.000066]\n",
      "631 [D loss: 0.999967] [G loss: 1.000060]\n",
      "632 [D loss: 0.999965] [G loss: 1.000061]\n",
      "633 [D loss: 0.999969] [G loss: 1.000061]\n",
      "634 [D loss: 0.999970] [G loss: 1.000068]\n",
      "635 [D loss: 0.999970] [G loss: 1.000061]\n",
      "636 [D loss: 0.999968] [G loss: 1.000061]\n",
      "637 [D loss: 0.999971] [G loss: 1.000066]\n",
      "638 [D loss: 0.999970] [G loss: 1.000063]\n",
      "639 [D loss: 0.999969] [G loss: 1.000065]\n",
      "640 [D loss: 0.999973] [G loss: 1.000070]\n",
      "641 [D loss: 0.999974] [G loss: 1.000067]\n",
      "642 [D loss: 0.999973] [G loss: 1.000068]\n",
      "643 [D loss: 0.999966] [G loss: 1.000068]\n",
      "644 [D loss: 0.999969] [G loss: 1.000063]\n",
      "645 [D loss: 0.999971] [G loss: 1.000059]\n",
      "646 [D loss: 0.999969] [G loss: 1.000062]\n",
      "647 [D loss: 0.999975] [G loss: 1.000070]\n",
      "648 [D loss: 0.999971] [G loss: 1.000065]\n",
      "649 [D loss: 0.999970] [G loss: 1.000060]\n",
      "650 [D loss: 0.999970] [G loss: 1.000062]\n",
      "651 [D loss: 0.999973] [G loss: 1.000064]\n",
      "652 [D loss: 0.999974] [G loss: 1.000068]\n",
      "653 [D loss: 0.999977] [G loss: 1.000057]\n",
      "654 [D loss: 0.999970] [G loss: 1.000064]\n",
      "655 [D loss: 0.999975] [G loss: 1.000058]\n",
      "656 [D loss: 0.999970] [G loss: 1.000061]\n",
      "657 [D loss: 0.999970] [G loss: 1.000064]\n",
      "658 [D loss: 0.999975] [G loss: 1.000064]\n",
      "659 [D loss: 0.999971] [G loss: 1.000072]\n",
      "660 [D loss: 0.999973] [G loss: 1.000071]\n",
      "661 [D loss: 0.999969] [G loss: 1.000069]\n",
      "662 [D loss: 0.999969] [G loss: 1.000063]\n",
      "663 [D loss: 0.999970] [G loss: 1.000067]\n",
      "664 [D loss: 0.999973] [G loss: 1.000066]\n",
      "665 [D loss: 0.999971] [G loss: 1.000069]\n",
      "666 [D loss: 0.999973] [G loss: 1.000059]\n",
      "667 [D loss: 0.999974] [G loss: 1.000065]\n",
      "668 [D loss: 0.999971] [G loss: 1.000060]\n",
      "669 [D loss: 0.999971] [G loss: 1.000063]\n",
      "670 [D loss: 0.999974] [G loss: 1.000062]\n",
      "671 [D loss: 0.999973] [G loss: 1.000067]\n",
      "672 [D loss: 0.999969] [G loss: 1.000068]\n",
      "673 [D loss: 0.999973] [G loss: 1.000066]\n",
      "674 [D loss: 0.999973] [G loss: 1.000068]\n",
      "675 [D loss: 0.999972] [G loss: 1.000064]\n",
      "676 [D loss: 0.999976] [G loss: 1.000065]\n",
      "677 [D loss: 0.999972] [G loss: 1.000068]\n",
      "678 [D loss: 0.999969] [G loss: 1.000071]\n",
      "679 [D loss: 0.999970] [G loss: 1.000064]\n",
      "680 [D loss: 0.999974] [G loss: 1.000066]\n",
      "681 [D loss: 0.999970] [G loss: 1.000069]\n",
      "682 [D loss: 0.999971] [G loss: 1.000068]\n",
      "683 [D loss: 0.999975] [G loss: 1.000065]\n",
      "684 [D loss: 0.999973] [G loss: 1.000064]\n",
      "685 [D loss: 0.999973] [G loss: 1.000066]\n",
      "686 [D loss: 0.999973] [G loss: 1.000060]\n",
      "687 [D loss: 0.999975] [G loss: 1.000066]\n",
      "688 [D loss: 0.999970] [G loss: 1.000064]\n",
      "689 [D loss: 0.999975] [G loss: 1.000064]\n",
      "690 [D loss: 0.999971] [G loss: 1.000074]\n",
      "691 [D loss: 0.999972] [G loss: 1.000065]\n",
      "692 [D loss: 0.999973] [G loss: 1.000067]\n",
      "693 [D loss: 0.999973] [G loss: 1.000064]\n",
      "694 [D loss: 0.999972] [G loss: 1.000062]\n",
      "695 [D loss: 0.999974] [G loss: 1.000067]\n",
      "696 [D loss: 0.999970] [G loss: 1.000064]\n",
      "697 [D loss: 0.999967] [G loss: 1.000061]\n",
      "698 [D loss: 0.999972] [G loss: 1.000064]\n",
      "699 [D loss: 0.999969] [G loss: 1.000065]\n",
      "700 [D loss: 0.999974] [G loss: 1.000060]\n",
      "701 [D loss: 0.999968] [G loss: 1.000064]\n",
      "702 [D loss: 0.999973] [G loss: 1.000065]\n",
      "703 [D loss: 0.999971] [G loss: 1.000063]\n",
      "704 [D loss: 0.999974] [G loss: 1.000065]\n",
      "705 [D loss: 0.999967] [G loss: 1.000069]\n",
      "706 [D loss: 0.999968] [G loss: 1.000069]\n",
      "707 [D loss: 0.999972] [G loss: 1.000064]\n",
      "708 [D loss: 0.999974] [G loss: 1.000069]\n",
      "709 [D loss: 0.999972] [G loss: 1.000066]\n",
      "710 [D loss: 0.999974] [G loss: 1.000064]\n",
      "711 [D loss: 0.999971] [G loss: 1.000060]\n",
      "712 [D loss: 0.999972] [G loss: 1.000066]\n",
      "713 [D loss: 0.999970] [G loss: 1.000068]\n",
      "714 [D loss: 0.999973] [G loss: 1.000068]\n",
      "715 [D loss: 0.999973] [G loss: 1.000065]\n",
      "716 [D loss: 0.999973] [G loss: 1.000058]\n",
      "717 [D loss: 0.999974] [G loss: 1.000064]\n",
      "718 [D loss: 0.999970] [G loss: 1.000061]\n",
      "719 [D loss: 0.999972] [G loss: 1.000065]\n",
      "720 [D loss: 0.999970] [G loss: 1.000067]\n",
      "721 [D loss: 0.999972] [G loss: 1.000068]\n",
      "722 [D loss: 0.999974] [G loss: 1.000065]\n",
      "723 [D loss: 0.999973] [G loss: 1.000065]\n",
      "724 [D loss: 0.999974] [G loss: 1.000064]\n",
      "725 [D loss: 0.999975] [G loss: 1.000069]\n",
      "726 [D loss: 0.999971] [G loss: 1.000056]\n",
      "727 [D loss: 0.999973] [G loss: 1.000065]\n",
      "728 [D loss: 0.999972] [G loss: 1.000069]\n",
      "729 [D loss: 0.999972] [G loss: 1.000065]\n",
      "730 [D loss: 0.999970] [G loss: 1.000060]\n",
      "731 [D loss: 0.999972] [G loss: 1.000061]\n",
      "732 [D loss: 0.999968] [G loss: 1.000068]\n",
      "733 [D loss: 0.999974] [G loss: 1.000065]\n",
      "734 [D loss: 0.999975] [G loss: 1.000062]\n",
      "735 [D loss: 0.999977] [G loss: 1.000067]\n",
      "736 [D loss: 0.999972] [G loss: 1.000067]\n",
      "737 [D loss: 0.999975] [G loss: 1.000065]\n",
      "738 [D loss: 0.999970] [G loss: 1.000066]\n",
      "739 [D loss: 0.999974] [G loss: 1.000070]\n",
      "740 [D loss: 0.999973] [G loss: 1.000067]\n",
      "741 [D loss: 0.999976] [G loss: 1.000064]\n",
      "742 [D loss: 0.999972] [G loss: 1.000065]\n",
      "743 [D loss: 0.999970] [G loss: 1.000074]\n",
      "744 [D loss: 0.999973] [G loss: 1.000061]\n",
      "745 [D loss: 0.999970] [G loss: 1.000065]\n",
      "746 [D loss: 0.999970] [G loss: 1.000067]\n",
      "747 [D loss: 0.999977] [G loss: 1.000064]\n",
      "748 [D loss: 0.999978] [G loss: 1.000065]\n",
      "749 [D loss: 0.999974] [G loss: 1.000062]\n",
      "750 [D loss: 0.999968] [G loss: 1.000064]\n",
      "751 [D loss: 0.999975] [G loss: 1.000057]\n",
      "752 [D loss: 0.999973] [G loss: 1.000064]\n",
      "753 [D loss: 0.999972] [G loss: 1.000063]\n",
      "754 [D loss: 0.999969] [G loss: 1.000063]\n",
      "755 [D loss: 0.999969] [G loss: 1.000062]\n",
      "756 [D loss: 0.999971] [G loss: 1.000064]\n",
      "757 [D loss: 0.999971] [G loss: 1.000069]\n",
      "758 [D loss: 0.999972] [G loss: 1.000068]\n",
      "759 [D loss: 0.999975] [G loss: 1.000057]\n",
      "760 [D loss: 0.999975] [G loss: 1.000062]\n",
      "761 [D loss: 0.999973] [G loss: 1.000063]\n",
      "762 [D loss: 0.999968] [G loss: 1.000068]\n",
      "763 [D loss: 0.999969] [G loss: 1.000064]\n",
      "764 [D loss: 0.999970] [G loss: 1.000060]\n",
      "765 [D loss: 0.999974] [G loss: 1.000062]\n",
      "766 [D loss: 0.999970] [G loss: 1.000061]\n",
      "767 [D loss: 0.999969] [G loss: 1.000065]\n",
      "768 [D loss: 0.999972] [G loss: 1.000063]\n",
      "769 [D loss: 0.999969] [G loss: 1.000060]\n",
      "770 [D loss: 0.999971] [G loss: 1.000067]\n",
      "771 [D loss: 0.999971] [G loss: 1.000074]\n",
      "772 [D loss: 0.999973] [G loss: 1.000067]\n",
      "773 [D loss: 0.999971] [G loss: 1.000063]\n",
      "774 [D loss: 0.999970] [G loss: 1.000066]\n",
      "775 [D loss: 0.999970] [G loss: 1.000070]\n",
      "776 [D loss: 0.999973] [G loss: 1.000069]\n",
      "777 [D loss: 0.999971] [G loss: 1.000066]\n",
      "778 [D loss: 0.999971] [G loss: 1.000068]\n",
      "779 [D loss: 0.999971] [G loss: 1.000065]\n",
      "780 [D loss: 0.999974] [G loss: 1.000060]\n",
      "781 [D loss: 0.999972] [G loss: 1.000064]\n",
      "782 [D loss: 0.999971] [G loss: 1.000060]\n",
      "783 [D loss: 0.999969] [G loss: 1.000062]\n",
      "784 [D loss: 0.999967] [G loss: 1.000064]\n",
      "785 [D loss: 0.999971] [G loss: 1.000070]\n",
      "786 [D loss: 0.999973] [G loss: 1.000066]\n",
      "787 [D loss: 0.999972] [G loss: 1.000066]\n",
      "788 [D loss: 0.999969] [G loss: 1.000064]\n",
      "789 [D loss: 0.999968] [G loss: 1.000064]\n",
      "790 [D loss: 0.999974] [G loss: 1.000060]\n",
      "791 [D loss: 0.999972] [G loss: 1.000064]\n",
      "792 [D loss: 0.999975] [G loss: 1.000065]\n",
      "793 [D loss: 0.999972] [G loss: 1.000065]\n",
      "794 [D loss: 0.999976] [G loss: 1.000066]\n",
      "795 [D loss: 0.999967] [G loss: 1.000068]\n",
      "796 [D loss: 0.999972] [G loss: 1.000071]\n",
      "797 [D loss: 0.999966] [G loss: 1.000056]\n",
      "798 [D loss: 0.999971] [G loss: 1.000059]\n",
      "799 [D loss: 0.999969] [G loss: 1.000058]\n",
      "800 [D loss: 0.999973] [G loss: 1.000067]\n",
      "801 [D loss: 0.999976] [G loss: 1.000073]\n",
      "802 [D loss: 0.999974] [G loss: 1.000061]\n",
      "803 [D loss: 0.999972] [G loss: 1.000070]\n",
      "804 [D loss: 0.999970] [G loss: 1.000065]\n",
      "805 [D loss: 0.999973] [G loss: 1.000057]\n",
      "806 [D loss: 0.999968] [G loss: 1.000066]\n",
      "807 [D loss: 0.999973] [G loss: 1.000066]\n",
      "808 [D loss: 0.999972] [G loss: 1.000057]\n",
      "809 [D loss: 0.999973] [G loss: 1.000056]\n",
      "810 [D loss: 0.999970] [G loss: 1.000064]\n",
      "811 [D loss: 0.999973] [G loss: 1.000063]\n",
      "812 [D loss: 0.999970] [G loss: 1.000061]\n",
      "813 [D loss: 0.999976] [G loss: 1.000067]\n",
      "814 [D loss: 0.999969] [G loss: 1.000069]\n",
      "815 [D loss: 0.999973] [G loss: 1.000067]\n",
      "816 [D loss: 0.999972] [G loss: 1.000067]\n",
      "817 [D loss: 0.999975] [G loss: 1.000067]\n",
      "818 [D loss: 0.999977] [G loss: 1.000069]\n",
      "819 [D loss: 0.999974] [G loss: 1.000059]\n",
      "820 [D loss: 0.999972] [G loss: 1.000065]\n",
      "821 [D loss: 0.999973] [G loss: 1.000065]\n",
      "822 [D loss: 0.999971] [G loss: 1.000063]\n",
      "823 [D loss: 0.999970] [G loss: 1.000067]\n",
      "824 [D loss: 0.999972] [G loss: 1.000062]\n",
      "825 [D loss: 0.999971] [G loss: 1.000066]\n",
      "826 [D loss: 0.999971] [G loss: 1.000063]\n",
      "827 [D loss: 0.999976] [G loss: 1.000057]\n",
      "828 [D loss: 0.999969] [G loss: 1.000069]\n",
      "829 [D loss: 0.999971] [G loss: 1.000067]\n",
      "830 [D loss: 0.999973] [G loss: 1.000069]\n",
      "831 [D loss: 0.999970] [G loss: 1.000065]\n",
      "832 [D loss: 0.999970] [G loss: 1.000060]\n",
      "833 [D loss: 0.999971] [G loss: 1.000063]\n",
      "834 [D loss: 0.999973] [G loss: 1.000063]\n",
      "835 [D loss: 0.999969] [G loss: 1.000060]\n",
      "836 [D loss: 0.999975] [G loss: 1.000056]\n",
      "837 [D loss: 0.999972] [G loss: 1.000063]\n",
      "838 [D loss: 0.999968] [G loss: 1.000065]\n",
      "839 [D loss: 0.999973] [G loss: 1.000059]\n",
      "840 [D loss: 0.999973] [G loss: 1.000066]\n",
      "841 [D loss: 0.999972] [G loss: 1.000066]\n",
      "842 [D loss: 0.999972] [G loss: 1.000070]\n",
      "843 [D loss: 0.999970] [G loss: 1.000060]\n",
      "844 [D loss: 0.999972] [G loss: 1.000062]\n",
      "845 [D loss: 0.999969] [G loss: 1.000065]\n",
      "846 [D loss: 0.999972] [G loss: 1.000069]\n",
      "847 [D loss: 0.999971] [G loss: 1.000065]\n",
      "848 [D loss: 0.999976] [G loss: 1.000064]\n",
      "849 [D loss: 0.999971] [G loss: 1.000062]\n",
      "850 [D loss: 0.999973] [G loss: 1.000059]\n",
      "851 [D loss: 0.999973] [G loss: 1.000067]\n",
      "852 [D loss: 0.999968] [G loss: 1.000062]\n",
      "853 [D loss: 0.999972] [G loss: 1.000064]\n",
      "854 [D loss: 0.999973] [G loss: 1.000063]\n",
      "855 [D loss: 0.999970] [G loss: 1.000063]\n",
      "856 [D loss: 0.999973] [G loss: 1.000061]\n",
      "857 [D loss: 0.999973] [G loss: 1.000057]\n",
      "858 [D loss: 0.999974] [G loss: 1.000063]\n",
      "859 [D loss: 0.999974] [G loss: 1.000062]\n",
      "860 [D loss: 0.999971] [G loss: 1.000066]\n",
      "861 [D loss: 0.999970] [G loss: 1.000062]\n",
      "862 [D loss: 0.999973] [G loss: 1.000057]\n",
      "863 [D loss: 0.999972] [G loss: 1.000067]\n",
      "864 [D loss: 0.999980] [G loss: 1.000066]\n",
      "865 [D loss: 0.999973] [G loss: 1.000068]\n",
      "866 [D loss: 0.999973] [G loss: 1.000060]\n",
      "867 [D loss: 0.999969] [G loss: 1.000060]\n",
      "868 [D loss: 0.999969] [G loss: 1.000067]\n",
      "869 [D loss: 0.999972] [G loss: 1.000064]\n",
      "870 [D loss: 0.999972] [G loss: 1.000067]\n",
      "871 [D loss: 0.999973] [G loss: 1.000065]\n",
      "872 [D loss: 0.999974] [G loss: 1.000062]\n",
      "873 [D loss: 0.999975] [G loss: 1.000057]\n",
      "874 [D loss: 0.999973] [G loss: 1.000064]\n",
      "875 [D loss: 0.999975] [G loss: 1.000064]\n",
      "876 [D loss: 0.999974] [G loss: 1.000060]\n",
      "877 [D loss: 0.999972] [G loss: 1.000064]\n",
      "878 [D loss: 0.999975] [G loss: 1.000062]\n",
      "879 [D loss: 0.999974] [G loss: 1.000057]\n",
      "880 [D loss: 0.999968] [G loss: 1.000068]\n",
      "881 [D loss: 0.999974] [G loss: 1.000059]\n",
      "882 [D loss: 0.999973] [G loss: 1.000063]\n",
      "883 [D loss: 0.999973] [G loss: 1.000060]\n",
      "884 [D loss: 0.999973] [G loss: 1.000066]\n",
      "885 [D loss: 0.999972] [G loss: 1.000071]\n",
      "886 [D loss: 0.999972] [G loss: 1.000065]\n",
      "887 [D loss: 0.999968] [G loss: 1.000067]\n",
      "888 [D loss: 0.999971] [G loss: 1.000069]\n",
      "889 [D loss: 0.999968] [G loss: 1.000065]\n",
      "890 [D loss: 0.999975] [G loss: 1.000065]\n",
      "891 [D loss: 0.999973] [G loss: 1.000060]\n",
      "892 [D loss: 0.999977] [G loss: 1.000062]\n",
      "893 [D loss: 0.999971] [G loss: 1.000063]\n",
      "894 [D loss: 0.999970] [G loss: 1.000064]\n",
      "895 [D loss: 0.999978] [G loss: 1.000059]\n",
      "896 [D loss: 0.999974] [G loss: 1.000069]\n",
      "897 [D loss: 0.999975] [G loss: 1.000064]\n",
      "898 [D loss: 0.999968] [G loss: 1.000061]\n",
      "899 [D loss: 0.999971] [G loss: 1.000066]\n",
      "900 [D loss: 0.999972] [G loss: 1.000063]\n",
      "901 [D loss: 0.999974] [G loss: 1.000062]\n",
      "902 [D loss: 0.999973] [G loss: 1.000063]\n",
      "903 [D loss: 0.999972] [G loss: 1.000060]\n",
      "904 [D loss: 0.999972] [G loss: 1.000070]\n",
      "905 [D loss: 0.999977] [G loss: 1.000061]\n",
      "906 [D loss: 0.999971] [G loss: 1.000065]\n",
      "907 [D loss: 0.999971] [G loss: 1.000059]\n",
      "908 [D loss: 0.999969] [G loss: 1.000063]\n",
      "909 [D loss: 0.999973] [G loss: 1.000057]\n",
      "910 [D loss: 0.999972] [G loss: 1.000058]\n",
      "911 [D loss: 0.999974] [G loss: 1.000058]\n",
      "912 [D loss: 0.999972] [G loss: 1.000059]\n",
      "913 [D loss: 0.999968] [G loss: 1.000055]\n",
      "914 [D loss: 0.999971] [G loss: 1.000050]\n",
      "915 [D loss: 0.999973] [G loss: 1.000071]\n",
      "916 [D loss: 0.999975] [G loss: 1.000062]\n",
      "917 [D loss: 0.999969] [G loss: 1.000060]\n",
      "918 [D loss: 0.999974] [G loss: 1.000059]\n",
      "919 [D loss: 0.999972] [G loss: 1.000067]\n",
      "920 [D loss: 0.999969] [G loss: 1.000063]\n",
      "921 [D loss: 0.999971] [G loss: 1.000058]\n",
      "922 [D loss: 0.999973] [G loss: 1.000067]\n",
      "923 [D loss: 0.999970] [G loss: 1.000062]\n",
      "924 [D loss: 0.999973] [G loss: 1.000063]\n",
      "925 [D loss: 0.999972] [G loss: 1.000057]\n",
      "926 [D loss: 0.999975] [G loss: 1.000071]\n",
      "927 [D loss: 0.999972] [G loss: 1.000059]\n",
      "928 [D loss: 0.999976] [G loss: 1.000063]\n",
      "929 [D loss: 0.999973] [G loss: 1.000067]\n",
      "930 [D loss: 0.999973] [G loss: 1.000066]\n",
      "931 [D loss: 0.999974] [G loss: 1.000066]\n",
      "932 [D loss: 0.999973] [G loss: 1.000059]\n",
      "933 [D loss: 0.999972] [G loss: 1.000061]\n",
      "934 [D loss: 0.999972] [G loss: 1.000066]\n",
      "935 [D loss: 0.999969] [G loss: 1.000065]\n",
      "936 [D loss: 0.999970] [G loss: 1.000065]\n",
      "937 [D loss: 0.999973] [G loss: 1.000059]\n",
      "938 [D loss: 0.999969] [G loss: 1.000060]\n",
      "939 [D loss: 0.999973] [G loss: 1.000057]\n",
      "940 [D loss: 0.999967] [G loss: 1.000064]\n",
      "941 [D loss: 0.999969] [G loss: 1.000066]\n",
      "942 [D loss: 0.999971] [G loss: 1.000067]\n",
      "943 [D loss: 0.999970] [G loss: 1.000063]\n",
      "944 [D loss: 0.999972] [G loss: 1.000061]\n",
      "945 [D loss: 0.999969] [G loss: 1.000058]\n",
      "946 [D loss: 0.999973] [G loss: 1.000065]\n",
      "947 [D loss: 0.999967] [G loss: 1.000062]\n",
      "948 [D loss: 0.999975] [G loss: 1.000060]\n",
      "949 [D loss: 0.999976] [G loss: 1.000065]\n",
      "950 [D loss: 0.999972] [G loss: 1.000062]\n",
      "951 [D loss: 0.999972] [G loss: 1.000064]\n",
      "952 [D loss: 0.999975] [G loss: 1.000064]\n",
      "953 [D loss: 0.999977] [G loss: 1.000062]\n",
      "954 [D loss: 0.999977] [G loss: 1.000061]\n",
      "955 [D loss: 0.999976] [G loss: 1.000067]\n",
      "956 [D loss: 0.999973] [G loss: 1.000064]\n",
      "957 [D loss: 0.999971] [G loss: 1.000064]\n",
      "958 [D loss: 0.999974] [G loss: 1.000066]\n",
      "959 [D loss: 0.999975] [G loss: 1.000060]\n",
      "960 [D loss: 0.999974] [G loss: 1.000058]\n",
      "961 [D loss: 0.999972] [G loss: 1.000062]\n",
      "962 [D loss: 0.999972] [G loss: 1.000060]\n",
      "963 [D loss: 0.999971] [G loss: 1.000062]\n",
      "964 [D loss: 0.999977] [G loss: 1.000065]\n",
      "965 [D loss: 0.999972] [G loss: 1.000066]\n",
      "966 [D loss: 0.999973] [G loss: 1.000064]\n",
      "967 [D loss: 0.999970] [G loss: 1.000067]\n",
      "968 [D loss: 0.999973] [G loss: 1.000065]\n",
      "969 [D loss: 0.999972] [G loss: 1.000062]\n",
      "970 [D loss: 0.999976] [G loss: 1.000062]\n",
      "971 [D loss: 0.999974] [G loss: 1.000060]\n",
      "972 [D loss: 0.999974] [G loss: 1.000056]\n",
      "973 [D loss: 0.999973] [G loss: 1.000066]\n",
      "974 [D loss: 0.999970] [G loss: 1.000061]\n",
      "975 [D loss: 0.999973] [G loss: 1.000061]\n",
      "976 [D loss: 0.999977] [G loss: 1.000061]\n",
      "977 [D loss: 0.999975] [G loss: 1.000060]\n",
      "978 [D loss: 0.999974] [G loss: 1.000064]\n",
      "979 [D loss: 0.999971] [G loss: 1.000063]\n",
      "980 [D loss: 0.999979] [G loss: 1.000058]\n",
      "981 [D loss: 0.999974] [G loss: 1.000061]\n",
      "982 [D loss: 0.999973] [G loss: 1.000068]\n",
      "983 [D loss: 0.999974] [G loss: 1.000064]\n",
      "984 [D loss: 0.999974] [G loss: 1.000062]\n",
      "985 [D loss: 0.999972] [G loss: 1.000066]\n",
      "986 [D loss: 0.999975] [G loss: 1.000068]\n",
      "987 [D loss: 0.999970] [G loss: 1.000065]\n",
      "988 [D loss: 0.999974] [G loss: 1.000059]\n",
      "989 [D loss: 0.999971] [G loss: 1.000062]\n",
      "990 [D loss: 0.999973] [G loss: 1.000061]\n",
      "991 [D loss: 0.999975] [G loss: 1.000062]\n",
      "992 [D loss: 0.999974] [G loss: 1.000064]\n",
      "993 [D loss: 0.999970] [G loss: 1.000069]\n",
      "994 [D loss: 0.999975] [G loss: 1.000058]\n",
      "995 [D loss: 0.999969] [G loss: 1.000058]\n",
      "996 [D loss: 0.999976] [G loss: 1.000059]\n",
      "997 [D loss: 0.999974] [G loss: 1.000059]\n",
      "998 [D loss: 0.999975] [G loss: 1.000063]\n",
      "999 [D loss: 0.999977] [G loss: 1.000062]\n",
      "1000 [D loss: 0.999972] [G loss: 1.000062]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAoIAAAHwCAYAAAAy8g5CAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nECQiIiLKUQwEiYiIiHLU/wNXpU+kTEpRFQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "wgan = WGAN()\n",
    "wgan.train(epochs=1001, batch_size = 64, sample_interval = 250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-4kcZsIRrRrY"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "WGAN",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
